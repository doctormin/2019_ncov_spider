{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "361c5ae9-67e8-493c-b15d-1c763400a7c3",
   "language": "python",
   "display_name": "'Python Interactive'"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "#41\n",
    "henan = 'http://wsjkw.henan.gov.cn/channels/854.shtml'         #卫健委的url\n",
    "info_pattern = re.compile(r'.*河南.*新.*冠.*疫情.*情况.*')  \n",
    "\n",
    "\n",
    "#找到通报疫情的url\n",
    "def find_url(web_address):\n",
    "    #获取网页信息\n",
    "    while(1):\n",
    "        try:\n",
    "            res = requests.get(web_address,timeout=(5, 10))\n",
    "            flag = 1\n",
    "            break\n",
    "        except:\n",
    "            print(\"retry\")\n",
    "            flag=0\n",
    "    res.encoding = 'utf-8'\n",
    "    \n",
    "    soup = BeautifulSoup(res.text, features = 'html.parser')      #结构化处理 \n",
    "    \n",
    "    for element in soup.find_all(name='ul',attrs = {'class':'list-group listmain'}):\n",
    "        for info in element.find_all('a'):\n",
    "            info_title = info.get_text() \n",
    "            print(info.get_text())     #获取通报的标题\n",
    "            if(info_pattern.match(info_title)):\n",
    "                return(info.get('href'))\n",
    "                \n",
    "info_url = find_url(henan)\n",
    "print(info_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_data(web_address):\n",
    "    #获取网页信息\n",
    "    while(1):\n",
    "        try:\n",
    "            res = requests.get(web_address,timeout=2)\n",
    "            flag=1\n",
    "            break\n",
    "        except:\n",
    "            print(\"retry\")\n",
    "            flag=0\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')      #结构化处理\n",
    "    for element in soup.find_all(name='div',attrs = {'id':'artibody'} ):\n",
    "        print(element.get_text())\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    print('begin')\n",
    "    get_data(info_url)\n",
    "    print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ]
}