{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "361c5ae9-67e8-493c-b15d-1c763400a7c3",
   "language": "python",
   "display_name": "'Python Interactive'"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "http://wjw.ah.gov.cn/news_details_54770.html\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import xlsxwriter\n",
    "import time\n",
    "import re\n",
    "#34\n",
    "anhui = 'http://wjw.ah.gov.cn/news_list_450_1.html'         #卫健委的url\n",
    "info_pattern = re.compile(r'.月.*日安徽省报告新型冠状病毒肺炎疫情情况')  \n",
    "\n",
    "\n",
    "#找到通报疫情的url\n",
    "def find_url(web_address):\n",
    "    #获取网页信息\n",
    "    while(1):\n",
    "        try:\n",
    "            res = requests.get(web_address,timeout=(5, 10))\n",
    "            flag = 1\n",
    "            break\n",
    "        except:\n",
    "            print(\"retry\")\n",
    "            flag=0\n",
    "    res.encoding = 'utf-8'\n",
    "    \n",
    "    soup = BeautifulSoup(res.text, features = 'html.parser')      #结构化处理 \n",
    "    \n",
    "    for element in soup.find_all(name='div',attrs = {'class':'list'}):\n",
    "        for info in element.find_all('a'):\n",
    "            info_title = info.get_text()      #获取通报的标题\n",
    "            if(info_pattern.match(info_title)):\n",
    "                return(info.get('href'))\n",
    "        \n",
    "\n",
    "        \n",
    "info_url = 'http://wjw.ah.gov.cn/'+find_url(anhui)\n",
    "print(info_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "begin\n",
      "\n",
      "       2020年2月9日0-24时，安徽省报告新增确诊病例51例，新增疑似病例61例，新增危重病例1例，新增治愈出院病例14例，新增死亡病例2例。\n",
      "        新增确诊病例中，合肥11例、亳州5例、宿州3例、蚌埠11例、阜阳7例、淮南1例、滁州1例、六安3例、芜湖1例、宣城1例、铜陵1例、池州3例、安庆3例，除危重病例外，其余均病情平稳。\n",
      "        新增疑似病例中，合肥4例、淮北3例、宿州2例、蚌埠25例、阜阳5例、淮南1例、六安11例、马鞍山1例、芜湖1例、铜陵4例、池州2例、安庆2例。\n",
      "        新增治愈出院病例中，淮北3例、宿州2例、阜阳2例、淮南1例、安庆6例。\n",
      "        新增死亡病例中，蚌埠2例。\n",
      "        截至2月9日24时，安徽省累计报告确诊病例830例，累计治愈出院病例73例，累计死亡病例3例，累计医学观察密切接触者17384人。\n",
      "        累计确诊病例中，其中合肥147例、淮北23例、亳州92例、宿州31例、蚌埠126例、阜阳125例、淮南23例、滁州12例、六安57例、马鞍山31例、芜湖30例、宣城6例、铜陵25例、池州15例、安庆78例、黄山9例。\n",
      "        截至2月9日24时，安徽省在院治疗确诊病例754例，其中危重症病例7例。\n",
      "        2月10日即将治愈出院16例，其中合肥4例、淮北1例、亳州2例、宿州1例、蚌埠1例、六安1例、滁州1例、池州2例、安庆3例。\n",
      "       死亡病例病情介绍：\n",
      "       患者杨某某，男，79岁，蚌埠市人，2月6日确诊，入住蚌医一附院（省级新冠肺炎重症集中收治基地医院），临床为危重症。患者既往有2型糖尿病、高血压病、冠状动脉粥样硬化性心脏病、运动神经元病。蚌医一附院第一时间组织专家组和重症治疗小组会商病情，全力进行救治，同时国家和省卫生健康委分别委派了专家指导诊疗。2月9日早上7：20突发心跳骤停，经抢救无效死亡。\n",
      "        患者赵某某，男，81岁，蚌埠市人，2月1日确诊，入住蚌埠市传染病医院，2月6日转入蚌医一附院（省级新冠肺炎重症集中收治基地医院），临床为危重症。患者既往有2型糖尿病、高血压病。蚌医一附院第一时间组织专家组和重症治疗小组会商病情，全力进行救治，同时国家和省卫生健康委分别委派了专家指导诊疗。2月9日上午11：30突发心跳骤停，经抢救无效死亡。\n",
      "\n",
      "\n",
      "finish\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def get_data(web_address):\n",
    "    #获取网页信息\n",
    "    while(1):\n",
    "        try:\n",
    "            res = requests.get(web_address,timeout=2)\n",
    "            flag=1\n",
    "            break\n",
    "        except:\n",
    "            print(\"retry\")\n",
    "            flag=0\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')      #结构化处理\n",
    "    for element in soup.find_all(name='div',attrs = {'class':'ar-artcon', 'id':'art_content'} ):\n",
    "        print(element.get_text())\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    print('begin')\n",
    "    get_data(info_url)\n",
    "    print('finish')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ]
}