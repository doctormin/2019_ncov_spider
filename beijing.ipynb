{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "' \\n                                2月9日北京市新冠肺炎防控工作新闻发布会疫情通报\\n\\t\\t\\t\\t\\t\\t\\t'\n",
      "http://wjw.beijing.gov.cn/xwzx_20031/wnxw/202002/t20200209_1627033.html\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "\n",
    "beijing = 'http://wjw.beijing.gov.cn/xwzx_20031/wnxw/'         #卫健委的url\n",
    "info_pattern1 = re.compile(r'.*北京.*新.*冠.*疫情通报.*')  \n",
    "info_pattern2 = re.compile(r'.*新增.*例.*')\n",
    "#找到通报疫情的url\n",
    "def find_url(web_address):\n",
    "    #获取网页信息\n",
    "    while(1):\n",
    "        try:\n",
    "            headers = {\"user-agent\": \"Mizilla/5.0\"}\n",
    "            res = requests.get(web_address,timeout=(5, 10), headers = headers)\n",
    "            flag = 1\n",
    "            break\n",
    "        except:\n",
    "            print(\"retry\")\n",
    "            flag=0\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.text, features = 'html.parser')      #结构化处理 \n",
    "    #print(soup)\n",
    "    for element in soup.find_all(name='div',attrs = {'class':'weinei_left_con'}):\n",
    "        for info in element.find_all('a'):\n",
    "            info_title = info.get_text()      #获取通报的标题\n",
    "            print(repr(info_title))\n",
    "            if info_pattern1.match(info_title.strip()) or info_pattern2.match(info_title.strip()):\n",
    "                return info.get('href')\n",
    "                \n",
    "info_url = 'http://wjw.beijing.gov.cn/xwzx_20031/wnxw' + find_url(beijing)[1:]\n",
    "print(info_url)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "begin\n",
      "北京市又有3例新冠肺炎患者，经过医护人员精心治疗后，符合出院标准，于2月8日先后从地坛医院、佑安医院出院。3名患者中，有2名男性，1名女性；年龄最小的35岁，最大的54岁。\n",
      "2月8日0时至24时，北京市新增11例新冠肺炎确诊病例。8例为确诊病例的密切接触者,3例否认湖北接触史，正在进一步核实。均已送至定点医疗机构进行救治。现有疑似病例184例，新增密切接触者217例，累计确定密切接触者1419例，其中548例已解除医学观察。\n",
      "截至2月8日24时,北京市累计确诊病例326例。东城区9例、西城区38例、朝阳区55例、海淀区52例、丰台区27例、石景山区13例、门头沟区3例、房山区14例、通州区16例、顺义区10例、昌平区17例、大兴区35例、怀柔区7例、密云区5例、延庆区1例，外地来京人员24例。平谷区尚未有病例。按照国家传染病信息网络报告规范，调整了我市确诊病例归属，将1例外地来京病例调整至海淀区。\n",
      "326例确诊病例中，男性病例158例，占48.5%，女性病例168例，占51.5%；年龄范围为6个月～94岁，其中5岁以下12例，占3.7%，6岁至17岁11例，占3.4%，18岁至59岁220例，占67.5%，60岁及以上83例，占25.4%。\n",
      "目前，北京市死亡2例，出院37例，287例在定点医院进行隔离治疗，其中危重型18例。\n",
      "finish\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def get_data(web_address):\n",
    "    #获取网页信息\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(info_url)\n",
    "    info_content = driver.find_element_by_xpath('//*[@id=\"zoom\"]/div').text.strip()\n",
    "    print(info_content)\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    print('begin')\n",
    "    get_data(info_url)\n",
    "    print('finish')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "361c5ae9-67e8-493c-b15d-1c763400a7c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}